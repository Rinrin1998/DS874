{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from dtaidistance import dtw\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_files(datafile_path, queryfile_path):\n",
    "    # Read the datafile and queryfile\n",
    "    datafile = pd.read_csv(datafile_path)\n",
    "    queryfile = pd.read_csv(queryfile_path, header=None)\n",
    "    \n",
    "    return datafile, queryfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which z-normalizes the data\n",
    "def z_normalize(datafile):\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on the datafile and transform the data\n",
    "    z_normalized_data = scaler.fit_transform(datafile)\n",
    "    \n",
    "    # Create a DataFrame for the z-normalized data\n",
    "    z_normalized_df = pd.DataFrame(z_normalized_data, columns=datafile.columns)\n",
    "    \n",
    "    # Get the mean and standard deviation used for normalization\n",
    "    mean = scaler.mean_\n",
    "    std_dev = scaler.scale_\n",
    "    \n",
    "    # Create a DataFrame for the mean and standard deviation\n",
    "    stats_df = pd.DataFrame({'Mean': mean, 'Standard Deviation': std_dev}, index=datafile.columns)\n",
    "    \n",
    "    return z_normalized_df, stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which minmax-normalizes the data\n",
    "def minmax_normalize(datafile):\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # Fit the scaler on the datafile and transform the data\n",
    "    minmax_normalized_data = scaler.fit_transform(datafile)\n",
    "    \n",
    "    # Create a DataFrame for the minmax-normalized data\n",
    "    minmax_normalized_df = pd.DataFrame(minmax_normalized_data, columns=datafile.columns)\n",
    "    \n",
    "    # Get the minimum and maximum values used for normalization\n",
    "    min_values = scaler.data_min_\n",
    "    max_values = scaler.data_max_\n",
    "    \n",
    "    # Create a DataFrame for the minimum and maximum values\n",
    "    minmax_stats_df = pd.DataFrame({'Minimum': min_values, 'Maximum': max_values}, index=datafile.columns)\n",
    "    \n",
    "    return minmax_normalized_df, minmax_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_distances(datafile, queryfile):\n",
    "    # Extract the query vector (assuming it's the first row of the queryfile)\n",
    "    query_vector = queryfile.iloc[0].values\n",
    "    \n",
    "    # Calculate cosine distances\n",
    "    distances = []\n",
    "    for index, row in datafile.iterrows():\n",
    "        distance = cosine(row.values, query_vector)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Add distances to the datafile DataFrame\n",
    "    datafile['Cosine Distance'] = distances\n",
    "    \n",
    "    # Sort the DataFrame by the 'Cosine Distance' column\n",
    "    sorted_datafile = datafile.sort_values(by='Cosine Distance')\n",
    "    \n",
    "    return sorted_datafile\n",
    "\n",
    "def calculate_euclidean_distances(datafile, queryfile):\n",
    "    # Extract the query vector (assuming it's the first row of the queryfile)\n",
    "    query_vector = queryfile.iloc[0].values\n",
    "    \n",
    "    # Calculate Euclidean distances\n",
    "    distances = []\n",
    "    for index, row in datafile.iterrows():\n",
    "        distance = euclidean(row.values, query_vector)\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Add distances to the datafile DataFrame\n",
    "    datafile['Euclidean Distance'] = distances\n",
    "    \n",
    "    # Sort the DataFrame by the 'Euclidean Distance' column\n",
    "    sorted_datafile = datafile.sort_values(by='Euclidean Distance')\n",
    "    \n",
    "    return sorted_datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m datafile_path = \u001b[33m'\u001b[39m\u001b[33mgt_2012.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     43\u001b[39m queryfile_path = \u001b[33m'\u001b[39m\u001b[33mqy_2013.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatafile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueryfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(datafile_path, queryfile_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m(datafile_path, queryfile_path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Read the CSV files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     datafile, queryfile= \u001b[43mread_csv_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatafile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueryfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(queryfile)\n\u001b[32m      6\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" #Calculate the z-normalized data and print the mean and standard deviation\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    # z_normalized_df, stats_df = z_normalize(datafile)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    # print(\"Z-normalized Datafile:\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    #print(\"\\nSorted Datafile by DTW Euclidean Distance:\")\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    #print(sorted_dtw_euclidean_datafile) \"\"\"\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mread_csv_files\u001b[39m\u001b[34m(datafile_path, queryfile_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_csv_files\u001b[39m(datafile_path, queryfile_path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Read the datafile and queryfile\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     datafile = \u001b[43mpd\u001b[49m.read_csv(datafile_path)\n\u001b[32m      4\u001b[39m     queryfile = pd.read_csv(queryfile_path, header=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m datafile, queryfile\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def main(datafile_path, queryfile_path):\n",
    "    # Read the CSV files\n",
    "    datafile, queryfile= read_csv_files(datafile_path, queryfile_path)\n",
    "    print(queryfile)\n",
    "    \n",
    "    \"\"\" #Calculate the z-normalized data and print the mean and standard deviation\n",
    "    # z_normalized_df, stats_df = z_normalize(datafile)\n",
    "    # print(\"Z-normalized Datafile:\")\n",
    "    # print(z_normalized_df)\n",
    "    # print(\"\\nMean and Standard Deviation:\")\n",
    "    # print(stats_df)\n",
    "\n",
    "    # Calculate the min-max normalized data and print the minimum and maximum values\n",
    "    # minmax_normalized_df, minmax_stats_df = minmax_normalize(datafile)\n",
    "    # print(\"MinMax-normalized Datafile:\")\n",
    "    # print(minmax_normalized_df)\n",
    "    # print(\"\\nMinimum and Maximum Values:\")\n",
    "    # print(minmax_stats_df)\n",
    "\n",
    "    # Calculate cosine distances and sort the datafile\n",
    "    # sorted_cosine_datafile = calculate_cosine_distances(datafile.copy(), queryfile)\n",
    "    # print(\"Sorted Datafile by Cosine Distance:\")\n",
    "    # print(sorted_cosine_datafile)\n",
    "    \n",
    "    # Calculate Euclidean distances and sort the datafile\n",
    "    #sorted_euclidean_datafile = calculate_euclidean_distances(datafile.copy(), queryfile)\n",
    "    #print(\"\\nSorted Datafile by Euclidean Distance:\")\n",
    "    #print(sorted_euclidean_datafile)\n",
    "\n",
    "    # Calculate DTW distances by Cosine and sort the datafile\n",
    "    # sorted_dtw_cosine_datafile = calculate_dtw_cosine(datafile.copy(), queryfile)\n",
    "    # print(\"\\nSorted Datafile by DTW Cosine Distance:\")\n",
    "    # print(sorted_dtw_cosine_datafile)\n",
    "\n",
    "    # Calculate DTW distances by Cosine and sort the datafile\n",
    "    #sorted_dtw_euclidean_datafile = calculate_dtw_euclidean(datafile.copy(), queryfile)\n",
    "    #print(\"\\nSorted Datafile by DTW Euclidean Distance:\")\n",
    "    #print(sorted_dtw_euclidean_datafile) \"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'datafile.csv' and 'queryfile.csv' with your actual file paths\n",
    "    datafile_path = 'gt_2012.csv'\n",
    "    queryfile_path = 'qy_2013.csv'\n",
    "    \n",
    "    main(datafile_path, queryfile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
